{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0oV8V4T2ePV",
        "outputId": "f295c8ba-5794-4e7b-aa77-dcbb4bbbf62b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (0.29.34)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2022.10.31)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m663.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.65.0)\n",
            "Collecting bitarray (from fairseq)\n",
            "  Downloading bitarray-2.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.7/273.7 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.22.4)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (16.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11170788 sha256=5b3f33220d7a2bebdd47e34bf4902e26e385edc3b0e76bc1aabc45d1746a2d20\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=2143def60d8a5980b8432f3d6ee5fe94457c64838a0fb4e7649eea6ca20c0fe8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.4 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.65.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=02c3e33f47f826a02c7d4445b5bc2158fbee40785ac1f1fa18a4913793100d67\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install fairseq sentencepiece sacremoses transformers tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTCvUA5T2vQ5",
        "outputId": "c60fa4be-6b8c-4dc1-d356-8244dac0ed91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import BertConfig, BertTokenizer, BertModel\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "7944cf9deaec4682aee62dd92b31e143",
            "8b5f281eaaf644c19bf525986f7b708c",
            "92c557c6ec8b43c8995b622e6b6da7a7",
            "82e6ddbb505f4167b7a1780aea764995",
            "09527454d37442338e36b7a39887a323",
            "b5721aae6e1d4c1f86c4ff954edd4d26",
            "0741cdd8d50345218fc5a178a02bf748",
            "c86dbf8bcd634a29bbd085755024e2d2",
            "01378f687f8149ceab74678ab4680520",
            "47252d9307854f7ea9233b9171494516",
            "a33768b5ae7d4694a3cae65f68d4a533",
            "10aac55564cf4e528b900ca36909c93b",
            "d27f2142d8bc4026aca7f3432876b81e",
            "a2b7af126f044f10b618d23fa68e28e1",
            "1fdff2dd7cd2454aaec0ef7308d2d644",
            "4c646a09e2064b978f7e458a3e02a353",
            "79b18370037844eab063d872550968e6",
            "8c65ac14028a48029e7b73fb2b9f2877",
            "17cd666632b24a788de2ca2e4e0c05f3",
            "42dadf0caf58462b9a73d56febc8636a",
            "b7768df5927e4579a5255c8effae32f0",
            "cc3da94e1bf64040b466a926bfa5571c",
            "f8c0450524854597bd206ae1fe55d8fa",
            "b7acebc57f964c26a77b9e1c1acabd95",
            "646135a7fce149c9aa0d5060398e5537",
            "e5a613383f454cc49ac3ac1a1ccb9cad",
            "734173969b93400e972f76690d866378",
            "ae6d4170568540ffbb9ba82b157f4ba8",
            "2df529d84d904cf49f7904212d09ac12",
            "242aa633ce61474daf20953ed60eb90c",
            "e0c968061dd6424e8fa5569f89ac01d9",
            "50544102dd4f4a5788be2f15ed511949",
            "182b0a8ed674468cb2809cb6338bc37e",
            "416d8d47ae5c47e1ab01ad8a8e67c0db",
            "ebb15d376ea9409ea799f565d957e390",
            "2c81501133384a1caa4aa64cd277b5c5",
            "d47b87496638411c8990fa309fa39724",
            "fb7fbf0658404ad8b810473c5836eef0",
            "436018cbdc504eb28b1f868bc5ab712a",
            "86fbb9d8de174f5c923bf65c4ddb8bdc",
            "6d43ad8ebd744606b89579604187a256",
            "be7fe1f6fc114aaa919dac4768122610",
            "1cbe794766734e45b707883d76b73b20",
            "422b1bd43f9046888fa2bc6d565502a9"
          ]
        },
        "id": "itKmd_cA2sCE",
        "outputId": "7b1c2dba-0f60-469a-f6a3-a3faa3b2311c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7944cf9deaec4682aee62dd92b31e143",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10aac55564cf4e528b900ca36909c93b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8c0450524854597bd206ae1fe55d8fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "416d8d47ae5c47e1ab01ad8a8e67c0db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "config = BertConfig.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "weights = model.get_input_embeddings().weight.detach().numpy()\n",
        "vocab = tokenizer.get_vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANCQpnNJ4r2-"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "base_data_dir = \"./data/tokenized_data\"\n",
        "for data_file in os.listdir(base_data_dir):\n",
        "# for data_file in ['test.en', 'test.fa']:\n",
        "    print(\"Process\", data_file)\n",
        "    with open(os.path.join(base_data_dir, data_file), 'r') as file:\n",
        "        data = file.read().splitlines()\n",
        "        tokenized_input = tokenizer.batch_encode_plus(data, add_special_tokens=True, max_length=16, padding='max_length', truncation=True)\n",
        "    lines = \"\"\n",
        "    for ids in tokenized_input['input_ids']:\n",
        "        tokens = tokenizer.convert_ids_to_tokens(ids)\n",
        "        lines += \" \".join(tokens)\n",
        "        lines += \"\\n\"\n",
        "    with open(os.path.join(\"data/encoded_data/\", data_file), 'w') as f:\n",
        "        f.write(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0EbSsQD_2sH6"
      },
      "outputs": [],
      "source": [
        "word_embeddings = []\n",
        "with open(os.path.join(\"./data/bert_weights.txt\"), 'w') as f:\n",
        "    for word, index in vocab.items():\n",
        "        embedding = weights[index]\n",
        "        line = word  + \" \" + \" \".join(map(str, embedding.tolist()[:512]))\n",
        "        f.write(f\"{line}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h7Yr2Ka2sKv",
        "outputId": "d7096946-9788-44a2-840f-6b7c0422ca9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-31 22:58:39.671107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-31 22:58:42 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-05-31 22:58:42 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='en', target_lang='fa', trainpref='./data/encoded_data/train', validpref='./data/encoded_data/valid', testpref='./data/encoded_data/test', align_suffix=None, destdir='./data/data_bin_bert/', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=40000, nwordssrc=40000, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=1, dict_only=False)\n",
            "2023-05-31 22:59:51 | INFO | fairseq_cli.preprocess | [en] Dictionary: 31280 types\n",
            "2023-05-31 23:01:18 | INFO | fairseq_cli.preprocess | [en] ./data/encoded_data/train.en: 670000 sents, 11390000 tokens, 0.0% replaced (by <unk>)\n",
            "2023-05-31 23:01:18 | INFO | fairseq_cli.preprocess | [en] Dictionary: 31280 types\n",
            "2023-05-31 23:01:18 | INFO | fairseq_cli.preprocess | [en] ./data/encoded_data/valid.en: 4000 sents, 68000 tokens, 0.00882% replaced (by <unk>)\n",
            "2023-05-31 23:01:18 | INFO | fairseq_cli.preprocess | [en] Dictionary: 31280 types\n",
            "2023-05-31 23:01:20 | INFO | fairseq_cli.preprocess | [en] ./data/encoded_data/test.en: 10000 sents, 170000 tokens, 0.0318% replaced (by <unk>)\n",
            "2023-05-31 23:01:20 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 31280 types\n",
            "2023-05-31 23:03:24 | INFO | fairseq_cli.preprocess | [fa] ./data/encoded_data/train.fa: 670000 sents, 11390000 tokens, 0.0% replaced (by <unk>)\n",
            "2023-05-31 23:03:24 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 31280 types\n",
            "2023-05-31 23:03:24 | INFO | fairseq_cli.preprocess | [fa] ./data/encoded_data/valid.fa: 4000 sents, 68000 tokens, 0.00147% replaced (by <unk>)\n",
            "2023-05-31 23:03:24 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 31280 types\n",
            "2023-05-31 23:03:27 | INFO | fairseq_cli.preprocess | [fa] ./data/encoded_data/test.fa: 10000 sents, 170000 tokens, 0.0% replaced (by <unk>)\n",
            "2023-05-31 23:03:27 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./data/data_bin_bert/\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ./data/data_bin_bert\n",
        "\n",
        "!fairseq-preprocess --source-lang en --target-lang fa \\\n",
        "  --trainpref ./data/encoded_data/train \\\n",
        "  --validpref ./data/encoded_data/valid \\\n",
        "  --testpref ./data/encoded_data/test \\\n",
        "  --nwordstgt 40000 \\\n",
        "  --nwordssrc 40000 \\\n",
        "  --joined-dictionary \\\n",
        "  --destdir ./data/data_bin_bert/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eapOAnrF6D9A",
        "outputId": "6ff464ae-eb0b-48c7-c36a-ee5e0a4d5d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-01 21:01:21.927559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-01 21:01:23 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2023-06-01 21:01:29 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './data/data_bin_bert/logs', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0025], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './data/data_bin_bert/checkpoints/', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='./data/data_bin_bert/logs', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=True, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm', max_epoch=5, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0025], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./data/data_bin_bert/checkpoints/', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=True, data='./data/data_bin_bert/', source_lang='en', target_lang='fa', load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=True, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, dropout=0.25, encoder_embed_path='./data/bert_weights.txt', decoder_embed_path='./data/bert_weights.txt', no_seed_provided=False, encoder_embed_dim=512, encoder_freeze_embed=False, encoder_hidden_size=512, encoder_layers=1, encoder_bidirectional=False, encoder_dropout_in=0.25, encoder_dropout_out=0.25, decoder_embed_dim=512, decoder_freeze_embed=False, decoder_hidden_size=512, decoder_layers=1, decoder_out_embed_dim=512, decoder_attention='1', decoder_dropout_in=0.25, decoder_dropout_out=0.25, adaptive_softmax_cutoff='10000,50000,200000', _name='lstm'), 'task': {'_name': 'translation', 'data': './data/data_bin_bert/', 'source_lang': 'en', 'target_lang': 'fa', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0025]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0025]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-06-01 21:01:30 | INFO | fairseq.tasks.translation | [en] dictionary: 31280 types\n",
            "2023-06-01 21:01:30 | INFO | fairseq.tasks.translation | [fa] dictionary: 31280 types\n",
            "2023-06-01 21:02:23 | INFO | fairseq.utils | found 31270/31280 types in embedding file\n",
            "2023-06-01 21:02:23 | INFO | fairseq_cli.train | LSTMModel(\n",
            "  (encoder): LSTMEncoder(\n",
            "    (dropout_in_module): FairseqDropout()\n",
            "    (dropout_out_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(31280, 512, padding_idx=1)\n",
            "    (lstm): LSTM(512, 512)\n",
            "  )\n",
            "  (decoder): LSTMDecoder(\n",
            "    (dropout_in_module): FairseqDropout()\n",
            "    (dropout_out_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(31280, 512, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0): LSTMCell(1024, 512)\n",
            "    )\n",
            "    (attention): AttentionLayer(\n",
            "      (input_proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (output_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2023-06-01 21:02:23 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2023-06-01 21:02:23 | INFO | fairseq_cli.train | model: LSTMModel\n",
            "2023-06-01 21:02:23 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2023-06-01 21:02:23 | INFO | fairseq_cli.train | num. shared model params: 22,052,864 (num. trained: 22,052,864)\n",
            "2023-06-01 21:02:23 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2023-06-01 21:02:25 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./data/data_bin_bert/valid.en-fa.en\n",
            "2023-06-01 21:02:25 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./data/data_bin_bert/valid.en-fa.fa\n",
            "2023-06-01 21:02:25 | INFO | fairseq.tasks.translation | ./data/data_bin_bert/ valid en-fa 4000 examples\n",
            "2023-06-01 21:02:36 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2023-06-01 21:02:36 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias\n",
            "2023-06-01 21:02:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-06-01 21:02:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2023-06-01 21:02:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-06-01 21:02:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2023-06-01 21:02:36 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2023-06-01 21:02:36 | INFO | fairseq.trainer | Preparing to load checkpoint ./data/data_bin_bert/checkpoints/checkpoint_last.pt\n",
            "2023-06-01 21:02:36 | INFO | fairseq.trainer | No existing checkpoint found ./data/data_bin_bert/checkpoints/checkpoint_last.pt\n",
            "2023-06-01 21:02:36 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2023-06-01 21:02:39 | INFO | fairseq.data.data_utils | loaded 670,000 examples from: ./data/data_bin_bert/train.en-fa.en\n",
            "2023-06-01 21:02:41 | INFO | fairseq.data.data_utils | loaded 670,000 examples from: ./data/data_bin_bert/train.en-fa.fa\n",
            "2023-06-01 21:02:41 | INFO | fairseq.tasks.translation | ./data/data_bin_bert/ train en-fa 670000 examples\n",
            "2023-06-01 21:02:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2792\n",
            "epoch 001:   0% 0/2792 [00:00<?, ?it/s]2023-06-01 21:02:41 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2023-06-01 21:02:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/usr/local/lib/python3.10/dist-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "epoch 001:  86% 2405/2792 [03:49<00:32, 11.84it/s, loss=7.004, nll_loss=4.407, ppl=21.21, wps=48254.6, ups=11.83, wpb=4080, bsz=240, num_updates=2400, lr=0.0015, gnorm=0.348, loss_scale=128, train_wall=8, gb_free=13, wall=233]2023-06-01 21:06:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "epoch 001: 100% 2791/2792 [04:32<00:00,  6.73it/s, loss=6.851, nll_loss=4.205, ppl=18.45, wps=36288.7, ups=8.89, wpb=4080, bsz=240, num_updates=2700, lr=0.0016875, gnorm=0.424, loss_scale=64, train_wall=10, gb_free=13, wall=263]2023-06-01 21:07:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/17 [00:00<?, ?it/s]\u001b[A2023-06-01 21:07:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بعد ##از ##ظهر از دو نفر از دو ##شن ##به, اما اگر ما [SEP]\n",
            "2023-06-01 21:07:16 | INFO | fairseq.tasks.translation | example reference: [CLS] بعد از ظهر من از دو به بعد ثابت است ولی اگر هم ##دی [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   6% 1/17 [00:01<00:27,  1.70s/it]\u001b[A2023-06-01 21:07:17 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] م ##تش ##کر ##م. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:07:17 | INFO | fairseq.tasks.translation | example reference: [CLS] م ##من ##ون. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  12% 2/17 [00:03<00:22,  1.49s/it]\u001b[A2023-06-01 21:07:18 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در پایان ماه مه, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:07:18 | INFO | fairseq.tasks.translation | example reference: [CLS] این آخر می است, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  18% 3/17 [00:04<00:19,  1.41s/it]\u001b[A2023-06-01 21:07:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:07:20 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  24% 4/17 [00:05<00:17,  1.37s/it]\u001b[A2023-06-01 21:07:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"ما در ##بار ##ه دو ##شن ##به ش ##ان ##زدهم [SEP]\n",
            "2023-06-01 21:07:21 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م, دو ##شن ##به ش ##ان ##زدهم یا پنج ##شن ##به نو [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  29% 5/17 [00:06<00:14,  1.19s/it]\u001b[A2023-06-01 21:07:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ن ##می ##ر گفت: \"ن ##یم ##ی, ه ##یج ##دهم, [SEP]\n",
            "2023-06-01 21:07:21 | INFO | fairseq.tasks.translation | example reference: [CLS] ام, آ ##ه, ه ##جد ##هم, سه - ش ##ن ##به [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  35% 6/17 [00:07<00:11,  1.07s/it]\u001b[A2023-06-01 21:07:22 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما من ف ##کر می ##کن ##م که ما ب ##تو ##انی ##م این [SEP]\n",
            "2023-06-01 21:07:22 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, من ت ##صور می ##کن ##م که او ##م زمان دیگری را [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  41% 7/17 [00:08<00:09,  1.01it/s]\u001b[A2023-06-01 21:07:23 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"با ##ش ##ه با ##ش ##ه, تا زمانی که [SEP]\n",
            "2023-06-01 21:07:23 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه با ##ش ##ه. شما گفت ##ید, تا ش ##ان ##زدهم [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  47% 8/17 [00:09<00:08,  1.05it/s]\u001b[A2023-06-01 21:07:24 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک روز دیگر در صورت ##ی که [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:07:24 | INFO | fairseq.tasks.translation | example reference: [CLS] پس من روز دیگری را تر ##جی ##ح می ##دهم, اگر, [SEP] [PAD]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  53% 9/17 [00:10<00:07,  1.00it/s]\u001b[A2023-06-01 21:07:25 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\", با وجود شما با شما چ ##یست? [SEP] [PAD]\n",
            "2023-06-01 21:07:25 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, آن برای شما مناسب است? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  59% 10/17 [00:11<00:07,  1.07s/it]\u001b[A2023-06-01 21:07:27 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه. چ ##را که ما در ده ##یم و ما در [SEP]\n",
            "2023-06-01 21:07:27 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه. چ ##را مثل ##ا در ساعت ده مل ##اقات ن [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  65% 11/17 [00:12<00:06,  1.11s/it]\u001b[A2023-06-01 21:07:28 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در ##وا ##قع من در هفت ##ه بعدی خ ##وا ##هم بود. [SEP] [PAD]\n",
            "2023-06-01 21:07:28 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب در ##وا ##قع من هفت ##هی آ ##ینده نیز خارج از شهر ه [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  71% 12/17 [00:14<00:06,  1.27s/it]\u001b[A2023-06-01 21:07:29 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"ما در ##بار ##ه ش ##ان ##زدهم ش ##ان ##زدهم [SEP]\n",
            "2023-06-01 21:07:29 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه ##وم جمع ##ه ش ##ان ##زدهم چه ##طور من تمام روز آزاد [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  76% 13/17 [00:15<00:05,  1.26s/it]\u001b[A2023-06-01 21:07:31 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, روز جمع ##ه, دو ساعت, دو ساعت, [SEP]\n",
            "2023-06-01 21:07:31 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه پس, جمع ##ه ساعت یک, دو ساعت با س [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  82% 14/17 [00:16<00:03,  1.20s/it]\u001b[A2023-06-01 21:07:31 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ن ##می ##م روز چهار ##شن ##به واقع ##ا کار ن ##می ##شود. [SEP]\n",
            "2023-06-01 21:07:31 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م چهار ##شن ##به واقع ##ا عمل ##ی نیست. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  88% 15/17 [00:17<00:02,  1.10s/it]\u001b[A2023-06-01 21:07:32 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] دو ##شن ##به چهار ##شن ##به است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:07:32 | INFO | fairseq.tasks.translation | example reference: [CLS] دو ##شن ##به چهار ##دهم, آ ##ه خوب است. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  94% 16/17 [00:18<00:01,  1.03s/it]\u001b[A2023-06-01 21:07:33 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"آ ##دم جمع ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:07:33 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##م جمع ##ه چ ##طور است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset: 100% 17/17 [00:18<00:00,  1.12it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-01 21:07:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.924 | nll_loss 3.011 | ppl 8.06 | bleu 55.2 | wps 3733.8 | wpb 4000 | bsz 235.3 | num_updates 2791\n",
            "2023-06-01 21:07:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 2791 updates\n",
            "2023-06-01 21:07:33 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint1.pt\n",
            "2023-06-01 21:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint1.pt\n",
            "2023-06-01 21:07:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data/data_bin_bert/checkpoints/checkpoint1.pt (epoch 1 @ 2791 updates, score 55.2) (writing took 11.105126522999967 seconds)\n",
            "2023-06-01 21:07:44 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2023-06-01 21:07:44 | INFO | train | epoch 001 | loss 8.235 | nll_loss 5.996 | ppl 63.82 | wps 37752.2 | ups 9.25 | wpb 4079.5 | bsz 240 | num_updates 2791 | lr 0.00174438 | gnorm 0.677 | loss_scale 64 | train_wall 259 | gb_free 13 | wall 308\n",
            "2023-06-01 21:07:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2792\n",
            "epoch 002:   0% 0/2792 [00:00<?, ?it/s]2023-06-01 21:07:44 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2023-06-01 21:07:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 002:  30% 835/2792 [01:21<02:44, 11.90it/s, loss=6.576, nll_loss=3.841, ppl=14.33, wps=44297.3, ups=10.89, wpb=4066.4, bsz=239.2, num_updates=3600, lr=0.00225, gnorm=0.288, loss_scale=64, train_wall=9, gb_free=13, wall=387]2023-06-01 21:09:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "epoch 002: 100% 2790/2792 [04:28<00:00, 12.82it/s, loss=6.297, nll_loss=3.476, ppl=11.12, wps=40086.7, ups=9.83, wpb=4080, bsz=240, num_updates=5500, lr=0.00213201, gnorm=0.21, loss_scale=32, train_wall=10, gb_free=13, wall=569]2023-06-01 21:12:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/17 [00:00<?, ?it/s]\u001b[A2023-06-01 21:12:14 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بعد ##از ##ظهر از دو تا آخر به پایان رسید, اما اگر ما [SEP]\n",
            "2023-06-01 21:12:14 | INFO | fairseq.tasks.translation | example reference: [CLS] بعد از ظهر من از دو به بعد ثابت است ولی اگر هم ##دی [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   6% 1/17 [00:01<00:16,  1.01s/it]\u001b[A2023-06-01 21:12:15 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] م ##تش ##کر ##م. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:12:15 | INFO | fairseq.tasks.translation | example reference: [CLS] م ##من ##ون. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  12% 2/17 [00:01<00:13,  1.09it/s]\u001b[A2023-06-01 21:12:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آخر ماه می است, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:12:16 | INFO | fairseq.tasks.translation | example reference: [CLS] این آخر می است, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  18% 3/17 [00:02<00:12,  1.13it/s]\u001b[A2023-06-01 21:12:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:12:16 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  24% 4/17 [00:03<00:11,  1.14it/s]\u001b[A2023-06-01 21:12:18 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد, چ ##گونه دو ##شن ##به ش ##ان ##زدهم یا پنج ##شن [SEP]\n",
            "2023-06-01 21:12:18 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م, دو ##شن ##به ش ##ان ##زدهم یا پنج ##شن ##به نو [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  29% 5/17 [00:04<00:11,  1.01it/s]\u001b[A2023-06-01 21:12:19 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد, چ ##گونه, ه ##جد ##هم, ن ##گاه ک ##نید [SEP]\n",
            "2023-06-01 21:12:19 | INFO | fairseq.tasks.translation | example reference: [CLS] ام, آ ##ه, ه ##جد ##هم, سه - ش ##ن ##به [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  35% 6/17 [00:05<00:11,  1.05s/it]\u001b[A2023-06-01 21:12:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما, من ف ##کر می ##کن ##م که ما به و ##اس ##طه [SEP]\n",
            "2023-06-01 21:12:20 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, من ت ##صور می ##کن ##م که او ##م زمان دیگری را [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  41% 7/17 [00:07<00:11,  1.10s/it]\u001b[A2023-06-01 21:12:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد با ##ش ##ه. شما تا ش ##ان ش ##ان ##زد ##ه [SEP]\n",
            "2023-06-01 21:12:21 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه با ##ش ##ه. شما گفت ##ید, تا ش ##ان ##زدهم [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  47% 8/17 [00:08<00:10,  1.14s/it]\u001b[A2023-06-01 21:12:22 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اگر یک روز دیگر را تر ##جی ##ح می ##دهم, [SEP] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:12:22 | INFO | fairseq.tasks.translation | example reference: [CLS] پس من روز دیگری را تر ##جی ##ح می ##دهم, اگر, [SEP] [PAD]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  53% 9/17 [00:09<00:09,  1.17s/it]\u001b[A2023-06-01 21:12:24 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"آ ##ه, با شما خوب است? [SEP] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:12:24 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, آن برای شما مناسب است? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  59% 10/17 [00:10<00:08,  1.21s/it]\u001b[A2023-06-01 21:12:25 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, چ ##را که چ ##را در ده سال و ما [SEP]\n",
            "2023-06-01 21:12:25 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه. چ ##را مثل ##ا در ساعت ده مل ##اقات ن [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  65% 11/17 [00:11<00:06,  1.10s/it]\u001b[A2023-06-01 21:12:26 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب, در ##وا ##قع من در هفت ##ه آ ##ینده از شهر بیرون [SEP]\n",
            "2023-06-01 21:12:26 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب در ##وا ##قع من هفت ##هی آ ##ینده نیز خارج از شهر ه [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  71% 12/17 [00:12<00:05,  1.02s/it]\u001b[A2023-06-01 21:12:26 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"احمد در مورد جمع ##ه ش ##ان ##زدهم تمام روز [SEP]\n",
            "2023-06-01 21:12:26 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه ##وم جمع ##ه ش ##ان ##زدهم چه ##طور من تمام روز آزاد [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  76% 13/17 [00:13<00:03,  1.04it/s]\u001b[A2023-06-01 21:12:27 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, جمع ##ه, ساعت دو ساعت, دو ساعت, [SEP]\n",
            "2023-06-01 21:12:27 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه پس, جمع ##ه ساعت یک, دو ساعت با س [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  82% 14/17 [00:14<00:02,  1.07it/s]\u001b[A2023-06-01 21:12:28 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد روز چهار ##شن ##به واقع ##ا کار نیست. [SEP] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:12:28 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م چهار ##شن ##به واقع ##ا عمل ##ی نیست. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  88% 15/17 [00:15<00:01,  1.08it/s]\u001b[A2023-06-01 21:12:29 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] دو ##شن ##به چهار ##دهم است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:12:29 | INFO | fairseq.tasks.translation | example reference: [CLS] دو ##شن ##به چهار ##دهم, آ ##ه خوب است. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  94% 16/17 [00:16<00:00,  1.11it/s]\u001b[A2023-06-01 21:12:30 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد چ ##گونه جمع ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:12:30 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##م جمع ##ه چ ##طور است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset: 100% 17/17 [00:16<00:00,  1.24it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-01 21:12:30 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.516 | nll_loss 2.498 | ppl 5.65 | bleu 58.87 | wps 4092.4 | wpb 4000 | bsz 235.3 | num_updates 5582 | best_bleu 58.87\n",
            "2023-06-01 21:12:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 5582 updates\n",
            "2023-06-01 21:12:30 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint2.pt\n",
            "2023-06-01 21:12:31 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint2.pt\n",
            "epoch 002: 100% 2790/2792 [04:47<00:00, 12.82it/s, loss=6.297, nll_loss=3.476, ppl=11.12, wps=40086.7, ups=9.83, wpb=4080, bsz=240, num_updates=5500, lr=0.00213201, gnorm=0.21, loss_scale=32, train_wall=10, gb_free=13, wall=569]2023-06-01 21:12:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data/data_bin_bert/checkpoints/checkpoint2.pt (epoch 2 @ 5582 updates, score 58.87) (writing took 4.834878439000022 seconds)\n",
            "2023-06-01 21:12:34 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2023-06-01 21:12:34 | INFO | train | epoch 002 | loss 6.476 | nll_loss 3.71 | ppl 13.09 | wps 39207.4 | ups 9.61 | wpb 4079.5 | bsz 240 | num_updates 5582 | lr 0.00211629 | gnorm 0.271 | loss_scale 32 | train_wall 256 | gb_free 13 | wall 598\n",
            "2023-06-01 21:12:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2792\n",
            "epoch 003:   0% 0/2792 [00:00<?, ?it/s]2023-06-01 21:12:35 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2023-06-01 21:12:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 003: 100% 2791/2792 [04:30<00:00, 12.90it/s, loss=6.104, nll_loss=3.23, ppl=9.38, wps=45330.8, ups=11.11, wpb=4080, bsz=240, num_updates=8300, lr=0.00173553, gnorm=0.193, loss_scale=32, train_wall=9, gb_free=13, wall=861]2023-06-01 21:17:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/17 [00:00<?, ?it/s]\u001b[A2023-06-01 21:17:06 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بعد ##از ##ظهر من از دو تا آخر, اما اگر ب ##گو ##یی [SEP]\n",
            "2023-06-01 21:17:06 | INFO | fairseq.tasks.translation | example reference: [CLS] بعد از ظهر من از دو به بعد ثابت است ولی اگر هم ##دی [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   6% 1/17 [00:00<00:15,  1.01it/s]\u001b[A2023-06-01 21:17:06 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] م ##تش ##کر ##م. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:17:06 | INFO | fairseq.tasks.translation | example reference: [CLS] م ##من ##ون. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  12% 2/17 [00:01<00:13,  1.10it/s]\u001b[A2023-06-01 21:17:07 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در پایان ماه مه, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:17:07 | INFO | fairseq.tasks.translation | example reference: [CLS] این آخر می است, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  18% 3/17 [00:02<00:12,  1.13it/s]\u001b[A2023-06-01 21:17:08 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:17:08 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  24% 4/17 [00:03<00:11,  1.15it/s]\u001b[A2023-06-01 21:17:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد, چ ##طور دو ##شن ##به ش ##ان ##زدهم یا پنج ##شن [SEP]\n",
            "2023-06-01 21:17:09 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م, دو ##شن ##به ش ##ان ##زدهم یا پنج ##شن ##به نو [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  29% 5/17 [00:04<00:10,  1.15it/s]\u001b[A2023-06-01 21:17:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد, چ ##گونه\" آ ##ه, ه ##جد ##هم ن ##گاه [SEP]\n",
            "2023-06-01 21:17:10 | INFO | fairseq.tasks.translation | example reference: [CLS] ام, آ ##ه, ه ##جد ##هم, سه - ش ##ن ##به [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  35% 6/17 [00:05<00:09,  1.15it/s]\u001b[A2023-06-01 21:17:11 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما من ف ##کر می ##کن ##م که ما می ##خ ##وا ##هیم و [SEP]\n",
            "2023-06-01 21:17:11 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, من ت ##صور می ##کن ##م که او ##م زمان دیگری را [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  41% 7/17 [00:06<00:08,  1.16it/s]\u001b[A2023-06-01 21:17:12 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"با ##ش ##ه. شما گفت ##ید که تا ش ##ان [SEP]\n",
            "2023-06-01 21:17:12 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه با ##ش ##ه. شما گفت ##ید, تا ش ##ان ##زدهم [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  47% 8/17 [00:07<00:08,  1.06it/s]\u001b[A2023-06-01 21:17:13 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک روز دیگر را تر ##جی ##ح می ##دهم, [SEP] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:17:13 | INFO | fairseq.tasks.translation | example reference: [CLS] پس من روز دیگری را تر ##جی ##ح می ##دهم, اگر, [SEP] [PAD]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  53% 9/17 [00:08<00:08,  1.02s/it]\u001b[A2023-06-01 21:17:14 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \", که با شما با شما است? [SEP] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:17:14 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, آن برای شما مناسب است? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  59% 10/17 [00:09<00:07,  1.07s/it]\u001b[A2023-06-01 21:17:15 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه. چ ##را ما هم ##دی ##گر را مل ##اقات ن [SEP]\n",
            "2023-06-01 21:17:15 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه. چ ##را مثل ##ا در ساعت ده مل ##اقات ن [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  65% 11/17 [00:10<00:06,  1.10s/it]\u001b[A2023-06-01 21:17:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خ ##ب, من هفت ##ه آ ##ینده شهر ه ##ست ##م. [SEP] [PAD]\n",
            "2023-06-01 21:17:16 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب در ##وا ##قع من هفت ##هی آ ##ینده نیز خارج از شهر ه [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  71% 12/17 [00:11<00:05,  1.13s/it]\u001b[A2023-06-01 21:17:18 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد چ ##طور در ##بار ##ه ش ##ان ##زدهم تمام روز آزاد است [SEP]\n",
            "2023-06-01 21:17:18 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه ##وم جمع ##ه ش ##ان ##زدهم چه ##طور من تمام روز آزاد [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  76% 13/17 [00:13<00:04,  1.15s/it]\u001b[A2023-06-01 21:17:19 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, جمع ##ه, ساعت, دو ساعت, [SEP] [PAD] [PAD]\n",
            "2023-06-01 21:17:19 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه پس, جمع ##ه ساعت یک, دو ساعت با س [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  82% 14/17 [00:14<00:03,  1.11s/it]\u001b[A2023-06-01 21:17:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد چهار ##شن ##به واقع ##ا کار ن ##می ##کن ##د. [SEP] [PAD]\n",
            "2023-06-01 21:17:20 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م چهار ##شن ##به واقع ##ا عمل ##ی نیست. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  88% 15/17 [00:15<00:02,  1.03s/it]\u001b[A2023-06-01 21:17:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] دو ##شن ##به چهار ##دهم است. \"[SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:17:20 | INFO | fairseq.tasks.translation | example reference: [CLS] دو ##شن ##به چهار ##دهم, آ ##ه خوب است. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  94% 16/17 [00:15<00:00,  1.02it/s]\u001b[A2023-06-01 21:17:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد چ ##طور در ##بار ##ه روز جمع ##ه است. [SEP] [PAD] [PAD]\n",
            "2023-06-01 21:17:21 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##م جمع ##ه چ ##طور است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset: 100% 17/17 [00:16<00:00,  1.16it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-01 21:17:21 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 5.372 | nll_loss 2.305 | ppl 4.94 | bleu 60.07 | wps 4118.1 | wpb 4000 | bsz 235.3 | num_updates 8374 | best_bleu 60.07\n",
            "2023-06-01 21:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 8374 updates\n",
            "2023-06-01 21:17:21 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint3.pt\n",
            "epoch 003: 100% 2791/2792 [04:46<00:00, 12.90it/s, loss=6.104, nll_loss=3.23, ppl=9.38, wps=45330.8, ups=11.11, wpb=4080, bsz=240, num_updates=8300, lr=0.00173553, gnorm=0.193, loss_scale=32, train_wall=9, gb_free=13, wall=861]2023-06-01 21:17:26 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint3.pt\n",
            "2023-06-01 21:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data/data_bin_bert/checkpoints/checkpoint3.pt (epoch 3 @ 8374 updates, score 60.07) (writing took 15.1737365030001 seconds)\n",
            "2023-06-01 21:17:36 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2023-06-01 21:17:36 | INFO | train | epoch 003 | loss 6.156 | nll_loss 3.294 | ppl 9.81 | wps 37732.7 | ups 9.25 | wpb 4079.5 | bsz 240 | num_updates 8374 | lr 0.00172784 | gnorm 0.199 | loss_scale 32 | train_wall 257 | gb_free 13 | wall 900\n",
            "2023-06-01 21:17:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2792\n",
            "epoch 004:   0% 0/2792 [00:00<?, ?it/s]2023-06-01 21:17:36 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2023-06-01 21:17:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 004: 100% 2791/2792 [04:26<00:00, 12.87it/s, loss=5.995, nll_loss=3.09, ppl=8.51, wps=39351.6, ups=9.65, wpb=4080, bsz=240, num_updates=11100, lr=0.00150075, gnorm=0.19, loss_scale=32, train_wall=10, gb_free=13, wall=1161]2023-06-01 21:22:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   0% 0/17 [00:00<?, ?it/s]\u001b[A2023-06-01 21:22:04 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بعد ##از ##ظهر من از دو تا پایان, اما اگر ب ##گو ##یی [SEP]\n",
            "2023-06-01 21:22:04 | INFO | fairseq.tasks.translation | example reference: [CLS] بعد از ظهر من از دو به بعد ثابت است ولی اگر هم ##دی [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   6% 1/17 [00:01<00:16,  1.01s/it]\u001b[A2023-06-01 21:22:04 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] م ##تش ##کر ##م. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:22:04 | INFO | fairseq.tasks.translation | example reference: [CLS] م ##من ##ون. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  12% 2/17 [00:01<00:13,  1.10it/s]\u001b[A2023-06-01 21:22:05 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پایان ماه مه, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:22:05 | INFO | fairseq.tasks.translation | example reference: [CLS] این آخر می است, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  18% 3/17 [00:02<00:12,  1.13it/s]\u001b[A2023-06-01 21:22:06 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:22:06 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  24% 4/17 [00:03<00:12,  1.03it/s]\u001b[A2023-06-01 21:22:08 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد, چ ##طور ش ##ان ##زدهم یا پنج ##شن ##به نو ##زدهم [SEP]\n",
            "2023-06-01 21:22:08 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م, دو ##شن ##به ش ##ان ##زدهم یا پنج ##شن ##به نو [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  29% 5/17 [00:05<00:12,  1.06s/it]\u001b[A2023-06-01 21:22:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] احمد گفت: \"احمد, چ ##گونه ه ##جد ##هم چ ##گونه است [SEP]\n",
            "2023-06-01 21:22:09 | INFO | fairseq.tasks.translation | example reference: [CLS] ام, آ ##ه, ه ##جد ##هم, سه - ش ##ن ##به [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  35% 6/17 [00:06<00:12,  1.10s/it]\u001b[A2023-06-01 21:22:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما من حد ##س می ##زن ##م که خ ##وا ##هیم رفت و \"[SEP]\n",
            "2023-06-01 21:22:10 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, من ت ##صور می ##کن ##م که او ##م زمان دیگری را [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  41% 7/17 [00:07<00:12,  1.24s/it]\u001b[A2023-06-01 21:22:11 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] احمد با ##ش ##ه گفت: \"با ##ش ##ه, تا ش ##ان [SEP]\n",
            "2023-06-01 21:22:11 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه با ##ش ##ه. شما گفت ##ید, تا ش ##ان ##زدهم [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  47% 8/17 [00:08<00:11,  1.23s/it]\u001b[A2023-06-01 21:22:13 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس من یک روز دیگر را تر ##جی ##ح می ##دهم, [SEP] [PAD] [PAD]\n",
            "2023-06-01 21:22:13 | INFO | fairseq.tasks.translation | example reference: [CLS] پس من روز دیگری را تر ##جی ##ح می ##دهم, اگر, [SEP] [PAD]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  53% 9/17 [00:10<00:09,  1.19s/it]\u001b[A2023-06-01 21:22:13 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آ ##ه, با ##ش ##ه? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:22:13 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, آن برای شما مناسب است? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  59% 10/17 [00:10<00:07,  1.08s/it]\u001b[A2023-06-01 21:22:14 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, پس چ ##را هم ##دی ##گر را مل ##اقات ن [SEP]\n",
            "2023-06-01 21:22:14 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه. چ ##را مثل ##ا در ساعت ده مل ##اقات ن [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  65% 11/17 [00:11<00:06,  1.02s/it]\u001b[A2023-06-01 21:22:15 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب در ##وا ##قع من در هفت ##ه آ ##ینده از شهر بیرون می [SEP]\n",
            "2023-06-01 21:22:15 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب در ##وا ##قع من هفت ##هی آ ##ینده نیز خارج از شهر ه [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  71% 12/17 [00:12<00:04,  1.03it/s]\u001b[A2023-06-01 21:22:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] احمد گفت: \"احمد چ ##طور روز جمع ##ه ش ##ان ##زدهم آزاد [SEP]\n",
            "2023-06-01 21:22:16 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه ##وم جمع ##ه ش ##ان ##زدهم چه ##طور من تمام روز آزاد [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  76% 13/17 [00:13<00:03,  1.07it/s]\u001b[A2023-06-01 21:22:17 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, جمع ##ه, ساعت, دو ساعت, [SEP] [PAD] [PAD]\n",
            "2023-06-01 21:22:17 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه پس, جمع ##ه ساعت یک, دو ساعت با س [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  82% 14/17 [00:14<00:02,  1.11it/s]\u001b[A2023-06-01 21:22:18 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد روز چهار ##شن ##به واقع ##ا کار ن ##می ##کن ##د. [SEP]\n",
            "2023-06-01 21:22:18 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م چهار ##شن ##به واقع ##ا عمل ##ی نیست. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  88% 15/17 [00:15<00:01,  1.13it/s]\u001b[A2023-06-01 21:22:19 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] دو ##شن ##به چهار ##دهم است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:22:19 | INFO | fairseq.tasks.translation | example reference: [CLS] دو ##شن ##به چهار ##دهم, آ ##ه خوب است. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  94% 16/17 [00:15<00:00,  1.14it/s]\u001b[A2023-06-01 21:22:19 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] احمد گفت: \"احمد چ ##طور است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:22:19 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##م جمع ##ه چ ##طور است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset: 100% 17/17 [00:16<00:00,  1.27it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-01 21:22:19 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.338 | nll_loss 2.266 | ppl 4.81 | bleu 60.35 | wps 4107.4 | wpb 4000 | bsz 235.3 | num_updates 11166 | best_bleu 60.35\n",
            "2023-06-01 21:22:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 11166 updates\n",
            "2023-06-01 21:22:19 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint4.pt\n",
            "epoch 004: 100% 2791/2792 [04:44<00:00, 12.87it/s, loss=5.995, nll_loss=3.09, ppl=8.51, wps=39351.6, ups=9.65, wpb=4080, bsz=240, num_updates=11100, lr=0.00150075, gnorm=0.19, loss_scale=32, train_wall=10, gb_free=13, wall=1161]2023-06-01 21:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint4.pt\n",
            "2023-06-01 21:22:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data/data_bin_bert/checkpoints/checkpoint4.pt (epoch 4 @ 11166 updates, score 60.35) (writing took 9.315248427999904 seconds)\n",
            "2023-06-01 21:22:28 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2023-06-01 21:22:29 | INFO | train | epoch 004 | loss 6.018 | nll_loss 3.119 | ppl 8.69 | wps 38982.4 | ups 9.56 | wpb 4079.5 | bsz 240 | num_updates 11166 | lr 0.00149631 | gnorm 0.192 | loss_scale 32 | train_wall 253 | gb_free 13 | wall 1192\n",
            "2023-06-01 21:22:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2792\n",
            "epoch 005:   0% 0/2792 [00:00<?, ?it/s]2023-06-01 21:22:29 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2023-06-01 21:22:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 005: 100% 2790/2792 [04:26<00:00, 12.85it/s, loss=5.938, nll_loss=3.019, ppl=8.1, wps=39719.6, ups=9.74, wpb=4080, bsz=240, num_updates=13900, lr=0.0013411, gnorm=0.188, loss_scale=32, train_wall=10, gb_free=13, wall=1454]2023-06-01 21:26:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   0% 0/17 [00:00<?, ?it/s]\u001b[A2023-06-01 21:26:56 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بعد ##از ##ظهر بعد از دو تا آخر, اما اگر ب ##گو ##یی [SEP]\n",
            "2023-06-01 21:26:56 | INFO | fairseq.tasks.translation | example reference: [CLS] بعد از ظهر من از دو به بعد ثابت است ولی اگر هم ##دی [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   6% 1/17 [00:01<00:16,  1.01s/it]\u001b[A2023-06-01 21:26:57 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] م ##تش ##کر ##م. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:26:57 | INFO | fairseq.tasks.translation | example reference: [CLS] م ##من ##ون. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  12% 2/17 [00:01<00:13,  1.10it/s]\u001b[A2023-06-01 21:26:58 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] این پایان ماه مه است, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:26:58 | INFO | fairseq.tasks.translation | example reference: [CLS] این آخر می است, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  18% 3/17 [00:02<00:12,  1.14it/s]\u001b[A2023-06-01 21:26:59 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:26:59 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب ##ه. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  24% 4/17 [00:03<00:12,  1.03it/s]\u001b[A2023-06-01 21:27:00 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"آ ##م, چ ##طور ش ##ان ##زدهم یا پنج ##شن ##به نو [SEP]\n",
            "2023-06-01 21:27:00 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م, دو ##شن ##به ش ##ان ##زدهم یا پنج ##شن ##به نو [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  29% 5/17 [00:04<00:12,  1.05s/it]\u001b[A2023-06-01 21:27:01 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"آ ##ه, چ ##گونه\" آ ##ه, ه ##جد [SEP]\n",
            "2023-06-01 21:27:01 | INFO | fairseq.tasks.translation | example reference: [CLS] ام, آ ##ه, ه ##جد ##هم, سه - ش ##ن ##به [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  35% 6/17 [00:06<00:13,  1.21s/it]\u001b[A2023-06-01 21:27:03 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما من ف ##کر می ##کن ##م که ما خ ##وا ##هیم رفت و [SEP]\n",
            "2023-06-01 21:27:03 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, من ت ##صور می ##کن ##م که او ##م زمان دیگری را [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  41% 7/17 [00:07<00:12,  1.20s/it]\u001b[A2023-06-01 21:27:04 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"با ##ش ##ه. شما گفت ##ید که تا ش ##ان [SEP]\n",
            "2023-06-01 21:27:04 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه با ##ش ##ه. شما گفت ##ید, تا ش ##ان ##زدهم [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  47% 8/17 [00:08<00:10,  1.20s/it]\u001b[A2023-06-01 21:27:05 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس من یک روز دیگر را تر ##جی ##ح می ##دهم, [SEP] [PAD] [PAD]\n",
            "2023-06-01 21:27:05 | INFO | fairseq.tasks.translation | example reference: [CLS] پس من روز دیگری را تر ##جی ##ح می ##دهم, اگر, [SEP] [PAD]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  53% 9/17 [00:09<00:09,  1.15s/it]\u001b[A2023-06-01 21:27:06 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"آ ##ه, آن با شما با شما? [SEP] [PAD] [PAD]\n",
            "2023-06-01 21:27:06 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, آن برای شما مناسب است? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  59% 10/17 [00:10<00:07,  1.05s/it]\u001b[A2023-06-01 21:27:07 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, پس چ ##را ن ##با ##ید ب ##گو ##یی ##م [SEP]\n",
            "2023-06-01 21:27:07 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه. چ ##را مثل ##ا در ساعت ده مل ##اقات ن [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  65% 11/17 [00:11<00:05,  1.01it/s]\u001b[A2023-06-01 21:27:08 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب در ##وا ##قع من در هفت ##ه آ ##ینده از شهر بیرون می [SEP]\n",
            "2023-06-01 21:27:08 | INFO | fairseq.tasks.translation | example reference: [CLS] خوب در ##وا ##قع من هفت ##هی آ ##ینده نیز خارج از شهر ه [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  71% 12/17 [00:12<00:04,  1.06it/s]\u001b[A2023-06-01 21:27:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"احمد چ ##طور در ##بار ##ه جمع ##ه ش ##ان [SEP]\n",
            "2023-06-01 21:27:09 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه ##وم جمع ##ه ش ##ان ##زدهم چه ##طور من تمام روز آزاد [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  76% 13/17 [00:13<00:03,  1.10it/s]\u001b[A2023-06-01 21:27:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, جمع ##ه, ساعت یک ساعت, دو ساعت, [SEP]\n",
            "2023-06-01 21:27:09 | INFO | fairseq.tasks.translation | example reference: [CLS] با ##ش ##ه پس, جمع ##ه ساعت یک, دو ساعت با س [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  82% 14/17 [00:14<00:02,  1.12it/s]\u001b[A2023-06-01 21:27:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" آ ##م, چهار ##شن ##به واقع ##ا کار ن [SEP]\n",
            "2023-06-01 21:27:10 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م چهار ##شن ##به واقع ##ا عمل ##ی نیست. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  88% 15/17 [00:14<00:01,  1.15it/s]\u001b[A2023-06-01 21:27:11 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] دو ##شن ##به چهار ##دهم, \"خوب است.\" [SEP] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:27:11 | INFO | fairseq.tasks.translation | example reference: [CLS] دو ##شن ##به چهار ##دهم, آ ##ه خوب است. [SEP] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 005: 100% 2790/2792 [04:42<00:00, 12.85it/s, loss=5.938, nll_loss=3.019, ppl=8.1, wps=39719.6, ups=9.74, wpb=4080, bsz=240, num_updates=13900, lr=0.0013411, gnorm=0.188, loss_scale=32, train_wall=10, gb_free=13, wall=1454]2023-06-01 21:27:12 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"آ ##م چ ##طور جمع ##ه چ ##طور است. [SEP] [PAD] [PAD] [PAD]\n",
            "2023-06-01 21:27:12 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##م جمع ##ه چ ##طور است. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset: 100% 17/17 [00:16<00:00,  1.28it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-01 21:27:12 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.274 | nll_loss 2.2 | ppl 4.59 | bleu 61.33 | wps 4153.1 | wpb 4000 | bsz 235.3 | num_updates 13958 | best_bleu 61.33\n",
            "2023-06-01 21:27:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 13958 updates\n",
            "2023-06-01 21:27:12 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint5.pt\n",
            "2023-06-01 21:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/data/data/data_bin_bert/checkpoints/checkpoint5.pt\n",
            "2023-06-01 21:27:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data/data_bin_bert/checkpoints/checkpoint5.pt (epoch 5 @ 13958 updates, score 61.33) (writing took 7.726534482000034 seconds)\n",
            "2023-06-01 21:27:19 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2023-06-01 21:27:19 | INFO | train | epoch 005 | loss 5.938 | nll_loss 3.016 | ppl 8.09 | wps 39150.7 | ups 9.6 | wpb 4079.5 | bsz 240 | num_updates 13958 | lr 0.00133832 | gnorm 0.191 | loss_scale 32 | train_wall 254 | gb_free 13 | wall 1483\n",
            "2023-06-01 21:27:19 | INFO | fairseq_cli.train | done training in 1478.4 seconds\n"
          ]
        }
      ],
      "source": [
        "!fairseq-train \\\n",
        "    \"./data/data_bin_bert/\" \\\n",
        "    --arch lstm --share-decoder-input-output-embed \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "    --lr 0.0025 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "    --dropout 0.25 --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-print-samples \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "    --fp16 --memory-efficient-fp16 \\\n",
        "    --max-epoch 5 \\\n",
        "    --encoder-embed-path ./data/bert_weights.txt \\\n",
        "    --decoder-embed-path ./data/bert_weights.txt \\\n",
        "    --share-all-embeddings \\\n",
        "    --source-lang en \\\n",
        "    --target-lang fa \\\n",
        "    --save-dir ./data/data_bin_bert/checkpoints/ \\\n",
        "    --tensorboard-logdir ./data/data_bin_bert/logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzJEnsS0wjB2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01378f687f8149ceab74678ab4680520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0741cdd8d50345218fc5a178a02bf748": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09527454d37442338e36b7a39887a323": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10aac55564cf4e528b900ca36909c93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d27f2142d8bc4026aca7f3432876b81e",
              "IPY_MODEL_a2b7af126f044f10b618d23fa68e28e1",
              "IPY_MODEL_1fdff2dd7cd2454aaec0ef7308d2d644"
            ],
            "layout": "IPY_MODEL_4c646a09e2064b978f7e458a3e02a353"
          }
        },
        "17cd666632b24a788de2ca2e4e0c05f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182b0a8ed674468cb2809cb6338bc37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cbe794766734e45b707883d76b73b20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fdff2dd7cd2454aaec0ef7308d2d644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7768df5927e4579a5255c8effae32f0",
            "placeholder": "​",
            "style": "IPY_MODEL_cc3da94e1bf64040b466a926bfa5571c",
            "value": " 714M/714M [00:09&lt;00:00, 55.9MB/s]"
          }
        },
        "242aa633ce61474daf20953ed60eb90c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c81501133384a1caa4aa64cd277b5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d43ad8ebd744606b89579604187a256",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be7fe1f6fc114aaa919dac4768122610",
            "value": 29
          }
        },
        "2df529d84d904cf49f7904212d09ac12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "416d8d47ae5c47e1ab01ad8a8e67c0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebb15d376ea9409ea799f565d957e390",
              "IPY_MODEL_2c81501133384a1caa4aa64cd277b5c5",
              "IPY_MODEL_d47b87496638411c8990fa309fa39724"
            ],
            "layout": "IPY_MODEL_fb7fbf0658404ad8b810473c5836eef0"
          }
        },
        "422b1bd43f9046888fa2bc6d565502a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42dadf0caf58462b9a73d56febc8636a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "436018cbdc504eb28b1f868bc5ab712a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47252d9307854f7ea9233b9171494516": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c646a09e2064b978f7e458a3e02a353": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50544102dd4f4a5788be2f15ed511949": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "646135a7fce149c9aa0d5060398e5537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_242aa633ce61474daf20953ed60eb90c",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0c968061dd6424e8fa5569f89ac01d9",
            "value": 995526
          }
        },
        "6d43ad8ebd744606b89579604187a256": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734173969b93400e972f76690d866378": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7944cf9deaec4682aee62dd92b31e143": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b5f281eaaf644c19bf525986f7b708c",
              "IPY_MODEL_92c557c6ec8b43c8995b622e6b6da7a7",
              "IPY_MODEL_82e6ddbb505f4167b7a1780aea764995"
            ],
            "layout": "IPY_MODEL_09527454d37442338e36b7a39887a323"
          }
        },
        "79b18370037844eab063d872550968e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e6ddbb505f4167b7a1780aea764995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47252d9307854f7ea9233b9171494516",
            "placeholder": "​",
            "style": "IPY_MODEL_a33768b5ae7d4694a3cae65f68d4a533",
            "value": " 625/625 [00:00&lt;00:00, 8.04kB/s]"
          }
        },
        "86fbb9d8de174f5c923bf65c4ddb8bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b5f281eaaf644c19bf525986f7b708c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5721aae6e1d4c1f86c4ff954edd4d26",
            "placeholder": "​",
            "style": "IPY_MODEL_0741cdd8d50345218fc5a178a02bf748",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "8c65ac14028a48029e7b73fb2b9f2877": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92c557c6ec8b43c8995b622e6b6da7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c86dbf8bcd634a29bbd085755024e2d2",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01378f687f8149ceab74678ab4680520",
            "value": 625
          }
        },
        "a2b7af126f044f10b618d23fa68e28e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17cd666632b24a788de2ca2e4e0c05f3",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42dadf0caf58462b9a73d56febc8636a",
            "value": 714314041
          }
        },
        "a33768b5ae7d4694a3cae65f68d4a533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae6d4170568540ffbb9ba82b157f4ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5721aae6e1d4c1f86c4ff954edd4d26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7768df5927e4579a5255c8effae32f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7acebc57f964c26a77b9e1c1acabd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae6d4170568540ffbb9ba82b157f4ba8",
            "placeholder": "​",
            "style": "IPY_MODEL_2df529d84d904cf49f7904212d09ac12",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "be7fe1f6fc114aaa919dac4768122610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c86dbf8bcd634a29bbd085755024e2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3da94e1bf64040b466a926bfa5571c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d27f2142d8bc4026aca7f3432876b81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79b18370037844eab063d872550968e6",
            "placeholder": "​",
            "style": "IPY_MODEL_8c65ac14028a48029e7b73fb2b9f2877",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "d47b87496638411c8990fa309fa39724": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cbe794766734e45b707883d76b73b20",
            "placeholder": "​",
            "style": "IPY_MODEL_422b1bd43f9046888fa2bc6d565502a9",
            "value": " 29.0/29.0 [00:00&lt;00:00, 408B/s]"
          }
        },
        "e0c968061dd6424e8fa5569f89ac01d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5a613383f454cc49ac3ac1a1ccb9cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50544102dd4f4a5788be2f15ed511949",
            "placeholder": "​",
            "style": "IPY_MODEL_182b0a8ed674468cb2809cb6338bc37e",
            "value": " 996k/996k [00:00&lt;00:00, 3.02MB/s]"
          }
        },
        "ebb15d376ea9409ea799f565d957e390": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_436018cbdc504eb28b1f868bc5ab712a",
            "placeholder": "​",
            "style": "IPY_MODEL_86fbb9d8de174f5c923bf65c4ddb8bdc",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "f8c0450524854597bd206ae1fe55d8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7acebc57f964c26a77b9e1c1acabd95",
              "IPY_MODEL_646135a7fce149c9aa0d5060398e5537",
              "IPY_MODEL_e5a613383f454cc49ac3ac1a1ccb9cad"
            ],
            "layout": "IPY_MODEL_734173969b93400e972f76690d866378"
          }
        },
        "fb7fbf0658404ad8b810473c5836eef0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
